# Real-Time ML Inference & Cloud Monitoring Dashboard
> **ATS Keywords:** `cloud computing` Â· `real-time ML inference` Â· `monitoring` Â· `multi-tenant infrastructure` Â· `data visualization` Â· `Prometheus` Â· `Grafana` Â· `Docker` Â· `Python` Â· `anomaly detection`

A **production-ready real-time ML inference pipeline** mimicking Google Cloud's ML operations infrastructure â€” with anomaly detection, live telemetry, Prometheus metrics scraping, Grafana dashboards, and Docker Compose deployment.

---

## ğŸ—ï¸ Architecture

```
IoT Sensor Stream
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FastAPI ML Inference Service            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Autoencoder + Isolation Forest Ensemble â”‚   â”‚
â”‚  â”‚  Predict â†’ score â†’ alert_level          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                  â”‚
â”‚  /predict        â†’ inference endpoint           â”‚
â”‚  /metrics        â†’ Prometheus scrape target     â”‚
â”‚  /dashboard      â†’ live HTML monitoring UI      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ metrics scrape (15s)
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   Prometheus    â”‚  â† time-series storage
              â”‚   :9090         â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ data source
                       â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚    Grafana      â”‚  â† dashboards, alerts
              â”‚    :3000        â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š What Gets Monitored

| Metric | Description | Alert Level |
|---|---|---|
| `ml_requests_total` | Total inference requests | â€” |
| `ml_anomaly_rate` | Fraction of anomalous predictions | > 15% = critical |
| `ml_latency_ms_avg` | Average inference latency | > 100ms = warning |
| `ml_latency_ms_p95` | 95th percentile latency | â€” |
| `ml_avg_anomaly_score` | Mean anomaly confidence score | â€” |
| `ml_drift_alerts_total` | Detected data distribution shifts | > 0 = alert |

---

## ğŸš€ Quick Start

### Option A: Without Docker (local)

```bash
# 1. Install dependencies
pip install -r requirements.txt

# 2. Train anomaly detection model
python model/train_anomaly.py

# 3. Start inference API
uvicorn serving.api:app --host 0.0.0.0 --port 8001

# 4. Start sensor simulator (in a new terminal)
python simulator/data_stream.py --mode mixed --rps 10

# 5. Open live dashboard
open http://localhost:8001/dashboard

# 6. View Prometheus metrics
curl http://localhost:8001/metrics
```

### Option B: Full Docker Stack (Prometheus + Grafana)

```bash
# 1. Build and start all services
docker-compose up --build

# Services:
# - ML API:     http://localhost:8001
# - Dashboard:  http://localhost:8001/dashboard
# - Prometheus: http://localhost:9090
# - Grafana:    http://localhost:3000 (admin/admin)
```

---

## ğŸ§  Model: Anomaly Detection Ensemble

| Component | Algorithm | Role |
|---|---|---|
| Autoencoder | PyTorch (8â†’4â†’8 latent) | Reconstruction-based scoring |
| Isolation Forest | sklearn | Tree-based outlier scoring |
| Ensemble | Weighted average (0.6 AE + 0.4 IF) | Final anomaly score |

**Input features**: temperature, vibration, pressure, current, voltage, frequency, power factor, humidity

**Result**:
- `anomaly_score`: 0.0â€“1.0 (higher = more anomalous)
- `alert_level`: "normal" / "warning" / "critical"

---

## ğŸ”Œ API Usage

### Single sensor prediction
```bash
curl -X POST http://localhost:8001/predict \
  -H "Content-Type: application/json" \
  -d '{
    "sensor_id": "machine_01",
    "temperature": 118.5,
    "vibration": 0.9,
    "pressure": 88.0,
    "current": 8.5,
    "voltage": 198.0,
    "frequency": 48.5,
    "power_factor": 0.72,
    "humidity": 55.0
  }'
```

Response:
```json
{
  "sensor_id": "machine_01",
  "is_anomaly": true,
  "anomaly_score": 0.8731,
  "alert_level": "critical",
  "latency_ms": 1.842
}
```

---

## ğŸ“ Project Structure

```
realtime-ml-monitoring/
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ train_anomaly.py       # Train AE + Isolation Forest ensemble
â”‚   â””â”€â”€ artifacts/             # Saved model artifacts (auto-generated)
â”œâ”€â”€ serving/
â”‚   â””â”€â”€ api.py                 # FastAPI server: /predict, /metrics, /dashboard
â”œâ”€â”€ simulator/
â”‚   â””â”€â”€ data_stream.py         # IoT sensor stream simulator
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus.yml         # Prometheus scrape config
â”‚   â””â”€â”€ grafana/
â”‚       â””â”€â”€ datasources.yml    # Auto-provisioned Prometheus datasource
â”œâ”€â”€ docker-compose.yml         # Full stack: API + Prometheus + Grafana
â”œâ”€â”€ Dockerfile.api             # ML API container
â”œâ”€â”€ Dockerfile.simulator       # Simulator container
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Tech Stack

| Component | Technology | GCP Equivalent |
|---|---|---|
| ML Model | PyTorch Autoencoder + sklearn | Vertex AI Anomaly Detection |
| Inference API | FastAPI + Uvicorn | Cloud Run |
| Metrics | Prometheus-compatible /metrics | Cloud Monitoring |
| Dashboard | Grafana | Cloud Monitoring Dashboards |
| Orchestration | Docker Compose | Cloud Run + Cloud Tasks |
| Data Stream | Custom simulator | Pub/Sub |

Feel Free To reach out
